# NSA-ViT Default Configuration
# Null-Space Absorbing ViT Compression

# Model
teacher_model: "vit_small_patch16_224"
teacher_checkpoint: null  # IMPORTANT: fine-tune first with `python -m nsa_vit.train_teacher --epochs 30`
image_size: 224
patch_size: 16
num_classes: 100  # CIFAR-100

# Compression
rank_selection_method: "energy_threshold"  # "energy_threshold" or "fixed_ratio"
energy_threshold: 0.95          # retain 95% spectral energy per layer
fixed_rank_ratio: 0.25          # alternative: keep 25% of min(m,n)
per_head_svd: true              # SVD per attention head, not fused
compress_patch_embed: false     # keep patch embedding full-rank
compress_head: false            # keep classifier head full-rank
trainable_pos_embed: true       # fine-tune positional embeddings

# Loss weights
alpha: 0.5            # null-space loss weight (core contribution)
gamma: 0.1            # attention-map distillation weight
eta: 0.1              # value-output matching weight (L_val)
beta: 1.0             # output KD weight (strong signal with proper teacher)
lambda_orth: 0.01     # orthonormality regularizer weight
mu: 0.01              # global CLS matching weight (L_global)
kd_temperature: 4.0
kd_metric: "kl"          # "kl" or "wasserstein" â€” KL is standard and proven
attn_loss_metric: "kl"   # "kl" (math-aligned) or "mse"

# Training
dataset: "cifar100"         # "cifar100" or "imagenet"
data_root: "./data"
batch_size: 128
epochs: 100
lr: 1e-4
weight_decay: 0.05
optimizer: "adamw"
scheduler: "cosine"
warmup_epochs: 3
gradient_clip: 1.0
num_workers: 4
seed: 42
device: "auto"  # "auto", "cuda", "mps", or "cpu"

# Data augmentation
mixup_alpha: 0.8        # Mixup alpha (0 to disable)
cutmix_alpha: 1.0       # CutMix alpha (0 to disable)
label_smoothing: 0.1    # Label smoothing factor

# Memory optimization
attn_loss_every_n: 3  # compute attention distillation every N blocks

# Logging & checkpoints
log_dir: "./runs"
checkpoint_dir: "./checkpoints"
save_every: 10
eval_every: 1

# Weights & Biases (set use_wandb: false to disable)
use_wandb: true
wandb_project: "nsa-vit"
wandb_entity: null   # optional: team or user name
wandb_run_name: null # optional: custom run name; null = auto
